{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bd9572",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680e41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python â‰¥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Common imports\n",
    "import os #It provides operating system operations.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import rand #It returns random values.\n",
    "from numpy.random import randn #It returns a sample from the standard normal distribution.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline \n",
    "import matplotlib as mpl \n",
    "\n",
    "# To create interactive plot\n",
    "import matplotlib.pyplot as plt #It provides a MATLAB-like way of plotting.\n",
    "\n",
    "# To load image\n",
    "import matplotlib.image as mpimg #It supports image loading, rescaling and display operations.\n",
    "\n",
    "#MaxNlocator: class used to select no more than N intervals at nice locations\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# To set labelsize\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import html\n",
    "#to do wordcloud data viz technique (greater words are the significant ones)\n",
    "#STOPWORDS is for removing unuseful words\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#countvect is to transform each doc (message) into a vector on the basis of the frequency of each word that occurs in the entire corpus\n",
    "#tfidfvect does the same of countvect but instead of frequency uses tf-idf for the weight of each word\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#lda for topic modelling: algo to find hidden topics (output) from preprocessed data (input)\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#interactive topic model visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "#to load more files and create a unique dataset\n",
    "import glob\n",
    "\n",
    "#\n",
    "import random\n",
    "#\n",
    "import gensim\n",
    "#\n",
    "import re, nltk, spacy, string\n",
    "\n",
    "#\n",
    "from pprint import pprint\n",
    "\n",
    "#\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#\n",
    "import collections\n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "\n",
    "#\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#\n",
    "import json\n",
    "\n",
    "#\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.point import Point\n",
    "\n",
    "#\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "#\n",
    "import time\n",
    "\n",
    "#\n",
    "import socket\n",
    "from urllib3.connection import HTTPConnection\n",
    "\n",
    "#\n",
    "import warnings\n",
    "\n",
    "#\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#\n",
    "import ast\n",
    "\n",
    "#\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "# Where to save the data, results and images\n",
    "PATH = \"../\"\n",
    "\n",
    "DATA_PATH = os.path.join(PATH, \"data\")\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "RESULTS_PATH = os.path.join(PATH, \"results\")\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "IMAGES_PATH = os.path.join(PATH, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    \n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0a11b",
   "metadata": {},
   "source": [
    "Consider the following documentation for the various libraries:\n",
    "\n",
    "1. [`numpy`](https://numpy.org/doc/)\n",
    "1. [`numpy.random.rand`](https://numpy.org/doc/reference/random/generated/numpy.random.rand.html)\n",
    "1. [`numpy.random.randn`](https://numpy.org/doc/reference/random/generated/numpy.random.randn.html)\n",
    "1. [`matplotlib`](https://matplotlib.org/)\n",
    "1. [`matplotlib.pyplot`](https://matplotlib.org/stable/api/pyplot_summary.html)\n",
    "1. [`matplotlib.image`](https://matplotlib.org/stable/api/image_api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a138c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
